# -*- coding: utf-8 -*-
"""Entrainement IA Bâtiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cPAoV9dLwWcaiTLXAqBXAhnvlT62g86N

## Importation des modules
"""

# Commented out IPython magic to ensure Python compatibility.
# On s'assure que toutes les modifications apportées aux bibliothèques sont automatiquement rechargées ici
# %reload_ext autoreload
# %autoreload 2

# On importe le module matpltlib afin de pouvoir afficher les graphiques pendant nos executions
# %matplotlib inline

#On importe le module files et os qui vont nous être utiles pour la suite du programme. 
from google.colab import files
import os

# Le module fastai va nous permettre d'avoir des résultats plus rapidement en termes de DeepLearning standard
from fastai.vision import *

# Evite les messages d'alertes du à l'obsolescence du module
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="torch.nn.functional")

"""## Télécharger le dataset via Kaggle

Pour télécharger votre token API, il vous faut ce rendre sur le lien suivant : 

https://www.kaggle.com/nomdutilisateur/account

Puis sur "*Create New API Token*".
"""

# Une fois votre token Kaggle
uploaded = files.upload()

# Renvoie les éléments du répertoire de travail 
os.listdir()

# On créer le  répertoire où l'on va mettre notre dataset 
! mkdir -p ~/.kaggle/
! mv kaggle.json ~/.kaggle/

# C'est le chemin, d'accès de notre dataset
chemin = Config.data_path()/'architecture'
chemin.mkdir(parents=True, exist_ok=True)
chemin

#On télécharge le dataset
! kaggle datasets download -d wwymak/architecture-dataset

#On s'assure que le dataset est bien téléchargé, en le voyant apparaître dans le répertoire de travail
os.listdir()

# Une fois bien téléchargé, on le met dans le répertoire, en dezipant
! unzip -q -n architecture-dataset.zip -d {chemin}

"""## Etude des données

Nous allons utiliser le jeu de données Architecture de Zhe Xu, qui présente 25 styles d'architecture. Notre modèle devra apprendre à faire la différence entre ces 25 catégories distinctes.
"""

os.listdir('/root/.fastai/data/architecture/arcDataset')

# Le chemin de notre data set est celui ci-dessous :
# chemin = '/root/.fastai/data/architecture/architectural-styles-dataset'

"""La première chose que nous faisons lorsque nous abordons un problème est d'examiner les données. Nous devons toujours bien comprendre la nature du problème et l'aspect des données avant de pouvoir déterminer comment le résoudre. Examiner les données signifie comprendre comment les répertoires de données sont structurés, quelles sont les étiquettes et à quoi ressemblent quelques exemples d'images.

Dans cet ensemble de données particulier, les étiquettes sont stockées dans le nom du dossier qui contient les images de chaque classe. Nous devrons les extraire pour pouvoir classer les images dans les bonnes catégories. La bibliothèque fastai a une fonction faite pour cela, `ImageDataBunch.from_folder`.
"""

# Cela va permettre de selectionner des images différentes, afin de s'assurer que nos résultats ne sont pas le fruit du hasard.
np.random.seed(42)

# On va transformer nos images afin d'augmenter notre dataset, on en parlera plus tard
tfms = get_transforms(do_flip=True, flip_vert=False, max_rotate=10, max_zoom=1.1, 
                      max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)

"""## Affichage des images, et études brèves du dataset"""

data = ImageDataBunch.from_folder(chemin, train=".", valid_pct=0.2,
        ds_tfms=tfms, size=224, num_workers=4, padding_mode='reflection', bs=64).normalize(imagenet_stats)

data.show_batch(rows=3, figsize=(9, 9))

data.classes, data.c, len(data.train_ds), len(data.valid_ds)

"""#### Augmentation de notre base de donnée

La fonction `get_transforms` nous a permis d'obtenir plus d'images pour l'entraînement, dans ce cas nous avons 9588 images au lieu des 4979 de l'ensemble de données original.

Ceci est réalisé en faisant quelques changements aux images et en les traitant comme des images nouvelles.

Retournement (juste horizontal), zoom, lumière, rotation, etc...
"""

def _plot(i,j,ax):
    x,y = data.train_ds[3]
    x.show(ax, y=y)

plot_multi(_plot, 3, 3, figsize=(8,8))

"""## Apprentissage : Constitution de notre réseau de neurones convolutifs

Maintenant que notre dataset d'images à été traité, nous pouvons dès à présent l'utiliser pour entraîner notre première couche de réseaux de neurones convolutifs. Pour cela, on va utiliser un réseau de neurones largement utilisé et déjà pré-entraînés sur notre modèle : resnet34. Ce réseau de neurones convolutifs ayant 34 couches de neurones

### Apprentissage

Ici, on va utiliser la fonction "cnn_learner" de la bibliothèque pytorch : Elle prend en entrée l'objet "data" (qui est notre dataset traité et normalisé précedemment), le nom du modèle (resnet34) et les paramètres que l'on cherche à observer (ici "l'accuracy" (précision) et le taux d'erreur)
"""

learn = cnn_learner(data, models.resnet34, metrics=[accuracy])

# Epochs = nombre de "tours" du réseaux de neurones que le modèle fait
# Valid_loss = résultat de la fonction de coût sur le jeu de données de validation
# Train_loss = résultat de la fonction de coût sur le jeu de données d'entraînement
#Accuracy = précision du modèle : c'est la proportion de bonnes prédiction

#Time = temps pour chaque epoch
learn.fit_one_cycle(5)

learn.save('stage-1-resnet34') #Par la fonction .save() de f permet d'enregistrer le réseaux "learn" dans le répertoire courant

interpretation = ClassificationInterpretation.from_learner(learn) #La bibliothèque fastai fournit la classe ClassificationInterpretation, on crée notre objet
#intepretation  
interp.plot_confusion_matrix(figsize=(12,12), title = "Matrice de confusion", cmap = "YlOrRd", dpi=70) #Méthode d'instance permettant d'afficher
# la matrice de confusion, le coefficient (i,j) de cette matrice affiche combiens de fois le j-ème élement a été prédit alors que la véritable valeur était le i-ème élement